{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Install Required Libraries\n",
        "Install the necessary libraries for the project."
      ],
      "metadata": {
        "id": "jrSM4XvJLT0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project showcases the power of MLOps in streamlining machine learning workflows. By automating data preprocessing and model training using Apache Airflow, the pipeline ensures efficiency, scalability, and reproducibility. This approach is essential for maintaining high standards of data quality and model performance in production environments.\n"
      ],
      "metadata": {
        "id": "q4A8F5CEMMb2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r90791klLGht"
      },
      "outputs": [],
      "source": [
        "!pip install pandas scikit-learn apache-airflow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Import Required Libraries\n",
        "Import the libraries needed for the project."
      ],
      "metadata": {
        "id": "XTAtC43fLX2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from airflow import DAG\n",
        "from airflow.operators.python import PythonOperator\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "OFBHxM8vLbTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3: Load and Preprocess the Dataset\n",
        "Load the dataset and perform preprocessing steps."
      ],
      "metadata": {
        "id": "HTJ2niQJLdPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('screentime_analysis.csv')\n",
        "\n",
        "# Check for missing values and duplicates\n",
        "print(data.isnull().sum())\n",
        "print(data.duplicated().sum())\n",
        "\n",
        "# Convert Date column to datetime and extract features\n",
        "data['Date'] = pd.to_datetime(data['Date'])\n",
        "data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "data['Month'] = data['Date'].dt.month\n",
        "\n",
        "# Encode the categorical 'App' column using one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['App'], drop_first=True)\n",
        "\n",
        "# Scale numerical features using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data[['Notifications', 'Times Opened']] = scaler.fit_transform(data[['Notifications', 'Times Opened']])\n",
        "\n",
        "# Feature engineering\n",
        "data['Previous_Day_Usage'] = data['Usage (minutes)'].shift(1)\n",
        "data['Notifications_x_TimesOpened'] = data['Notifications'] * data['Times Opened']\n",
        "\n",
        "# Save the preprocessed data to a file\n",
        "data.to_csv('preprocessed_screentime_analysis.csv', index=False)"
      ],
      "metadata": {
        "id": "s0cw7Zi4LfUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4: Train the Model\n",
        "Train a Random Forest model to predict app usage."
      ],
      "metadata": {
        "id": "2jSxJo18LheN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target variable\n",
        "X = data.drop(columns=['Usage (minutes)', 'Date'])\n",
        "y = data['Usage (minutes)']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = RandomForestRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "predictions = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print(f'Mean Absolute Error: {mae}')"
      ],
      "metadata": {
        "id": "qqZ7BarXLkTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5: Define the Data Preprocessing Function for Airflow\n",
        "Define the function to preprocess data, which will be used in the Airflow DAG."
      ],
      "metadata": {
        "id": "vT48egdcLl0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data():\n",
        "    file_path = 'screentime_analysis.csv'\n",
        "    data = pd.read_csv(file_path)\n",
        "\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "    data['Month'] = data['Date'].dt.month\n",
        "\n",
        "    data = data.drop(columns=['Date'])\n",
        "\n",
        "    data = pd.get_dummies(data, columns=['App'], drop_first=True)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    data[['Notifications', 'Times Opened']] = scaler.fit_transform(data[['Notifications', 'Times Opened']])\n",
        "\n",
        "    preprocessed_path = 'preprocessed_screentime_analysis.csv'\n",
        "    data.to_csv(preprocessed_path, index=False)\n",
        "    print(f\"Preprocessed data saved to {preprocessed_path}\")"
      ],
      "metadata": {
        "id": "HxcSc7GRLoCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6: Define the Airflow DAG\n",
        "Define the Airflow DAG to schedule the preprocessing task."
      ],
      "metadata": {
        "id": "ePsggjNBLrAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dag = DAG(\n",
        "    dag_id='data_preprocessing',\n",
        "    schedule_interval='@daily',\n",
        "    start_date=datetime(2025, 1, 1),\n",
        "    catchup=False,\n",
        ")\n",
        "\n",
        "preprocess_task = PythonOperator(\n",
        "    task_id='preprocess',\n",
        "    python_callable=preprocess_data,\n",
        "    dag=dag,\n",
        ")"
      ],
      "metadata": {
        "id": "hXGAgFzuLuBs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}